{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preliminary Imports and Defining Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Custom Error to Handle Entries Incompatible for the Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UnableToCreateTableError(Exception):\n",
    "    def __init__(self, message = 'The number of entries in the scraped column does not equal the number of columns provided; thus, Pandas won\\'t be able to create this table.'):\n",
    "        self.message = message\n",
    "        super().__init__(self.message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the Column Names for the Table "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Column names from the website\n",
    "\n",
    "advanced = 'Player, Pos, Age, Tm, G, MP, PER, TS%, 3PAr, FTr, ORB%, DRB%, TRB%, AST%, STL%, BLK%, TOV%, '\n",
    "advanced += 'USG%, , OWS, DWS, WS, WS/48, , OBPM, DBPM, BPM, VORP'\n",
    "adv_cols = advanced.split(', ')\n",
    "\n",
    "per100 = 'Player, Pos, Age, Tm, G, GS, MP, FG, FGA, FG%, 3P, 3PA, 3P%, 2P, 2PA, 2P%, FT, '\n",
    "per100 += 'FTA, FT%, ORB, DRB, TRB, AST, STL, BLK, TOV, PF, PTS, , ORtg, DRtg'\n",
    "cols_100 = per100.split(', ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrape the Data for Two Different Relevant Pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_to_df(nba_url, columns):\n",
    "    '''\n",
    "    Inputs:\n",
    "    nba_url - A string representing the URL of the NBA page you are trying to scrape\n",
    "    columns - A list of strings containing the names of the columns in the DataFrame\n",
    "              you're trying to create\n",
    "    timeline - A string with the part of the season in which you're scraping the data\n",
    "    \n",
    "    This function scrapes the page given by the URL and finds the table object. It then\n",
    "    creates a pandas DataFrame and saves it to a .csv file in the same directory.\n",
    "    \n",
    "    Returns:\n",
    "    None\n",
    "    '''\n",
    "    \n",
    "    #Get the html for the given url\n",
    "    page = requests.get(url)\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    \n",
    "    #Find tables in the html\n",
    "    table = soup.find('table')\n",
    "    table_body = table.find('tbody')\n",
    "\n",
    "    #Get the rows of the table\n",
    "    rows = table_body.find_all('tr')\n",
    "    \n",
    "    #Parse each row of data and convert entries to the correct data types\n",
    "    data = []\n",
    "    for row in rows:\n",
    "        cols = row.find_all('td')\n",
    "        cols = [ele.text.strip() for ele in cols]\n",
    "        if len(cols) == 0:\n",
    "            continue\n",
    "        else:\n",
    "            try:\n",
    "                assert len(cols) == len(columns)\n",
    "            except:\n",
    "                raise UnableToCreateTableError()\n",
    "            for i in range(len(cols)):\n",
    "                if i not in [0,1,3]:\n",
    "                    if cols[i] == '':\n",
    "                        cols[i] = 0.0\n",
    "                    else:\n",
    "                        cols[i] = float(cols[i])\n",
    "            data.append(cols)\n",
    "            \n",
    "    nba = pd.DataFrame(data = data, columns = columns)\n",
    "    nba = nba.drop_duplicates(subset = 'Player', keep = 'last')\n",
    "    return nba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "season100 = 'https://www.basketball-reference.com/leagues/NBA_2020_per_poss.html'\n",
    "season_adv = 'https://www.basketball-reference.com/leagues/NBA_2020_advanced.html'\n",
    "playoffs100 = 'https://www.basketball-reference.com/playoffs/NBA_2020_per_poss.html'\n",
    "playoffs_adv = 'https://www.basketball-reference.com/playoffs/NBA_2020_advanced.html'\n",
    "\n",
    "urls = [season100, season_adv, playoffs100, playoffs_adv]\n",
    "cols = [cols_100, adv_cols, cols_100, adv_cols]\n",
    "\n",
    "dfs = []\n",
    "for url, names in zip(urls, cols):\n",
    "    temp = scrape_to_df(url, names)\n",
    "    dfs.append(temp)\n",
    "\n",
    "assert len(dfs) == 4, len(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-7cab45520779>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  temp['%Usage'] = dfs[2*i + 1]['USG%']\n"
     ]
    }
   ],
   "source": [
    "for i in range(2):\n",
    "    temp = dfs[2*i][['Player', 'Tm', 'ORtg', 'DRtg']]\n",
    "    temp['%Usage'] = dfs[2*i + 1]['USG%']\n",
    "    if i == 0:\n",
    "        temp.to_csv('Star_Player_Statistics_Season.csv', index = False)\n",
    "    else:\n",
    "        temp.to_csv('Star_Player_Statistics_Playoffs.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
